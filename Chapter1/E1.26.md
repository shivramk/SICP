Consider the given code

~~~~~ {#mycode .scheme}
(define (expmod base exp m)
 (cond ((= exp 0) 1)
  ((even? exp) (remainder
      (* (expmod base (/ exp 2) m)
         (expmod base (/ exp 2) m)) m))
  (else (remainder
      (* base (expmod base (- exp 1) m)) m))))
~~~~~

The problem here is the multiplication of `(expmod base (/ exp 2) m)` by itself.
If the square function were being used, the expression \texttt{(expmod base (/ exp 2) m)}
would be evaluated only once. But now it is being evaluated twice. This changes
the complexity from $O(log(n))$ to $O(n)$

Proof by example

1. In the base case where $exp = 0$
$$
\begin{aligned}
steps(0) &= 1
\end{aligned}
$$

2. When $exp = 1$
$$
\begin{aligned}
steps(1) &= 2
\end{aligned}
$$

3. For $exp = 2$
$$
\begin{aligned}
steps(2) &= 2 * steps(1) \\
& = 2 * 2 \\
& = 4
\end{aligned}
$$

4. For $exp = n$
$$
\begin{aligned}
steps &= 2 * (steps(n-1)) \\
& = 2 * n \\
& = 2n
\end{aligned}
$$

Hence the order of growth is $\Theta(n)$

Proof by [Master theorem](http://en.wikipedia.org/wiki/Master_theorem)

1. The recurrence relation for the order of growth of this process can be
written as
$$\begin{aligned}T(n) = aT(\frac{n}{b}) + f(n)\end{aligned}$$

2. In this case (where $a=2, b=2$ and $f(n)=k$ where k is a constant)
$$\begin{aligned}T(n) = 2T(\frac{n}{2}) + k\end{aligned}$$

3. The master method says that if
               $f(n) = O(n^{(\log_b{a}-\epsilon)})$ for some constant $\epsilon > 0$ then
               $T(n) = \Theta(n^{\log_b{a}})$

4. Substituting the values of a and b we get
$$
\begin{aligned}
T(n) &= \Theta(n^{\log_b{a}}) \\
& = \Theta(n^{\log_2{2}}) \\
& = \Theta(n^1) \\
& = \Theta(n)
\end{aligned}
$$
